{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600744063616",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## This notebook will walk you through cleaning up noisy V4 Miniscope data\n",
    "\n",
    "Post questions or issues to the Miniscope Google Group: https://groups.google.com/g/miniscope\n",
    "\n",
    "You will need the following packages installed (you likely should great a virtual python environment using conda or similar). You can use 'pip install <package name> \n",
    "\n",
    "* opencv-python\n",
    "* matplotlib\n",
    "* tqdm\n",
    "* scipy\n",
    "* ipympl\n",
    "* ipython\n",
    "\n",
    "If a video is playing you can hit 'q' to quit the playback\n",
    "\n",
    "- Aharoni Lab\n",
    "- 09/18/2020\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm \n",
    "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
    "\n",
    "\n",
    "# Need pip install ipympl\n",
    "%matplotlib widget\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)"
   ]
  },
  {
   "source": [
    "Enter the path to where your V4 Miniscope videos are saved."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directory where videos are stored\n",
    "\n",
    "\n",
    "# Data files should be .avi's and have the following form:\n",
    "# '<dataDir><dataFilePrefix><startingFileNum>.avi'\n",
    "\n",
    "# Values users can modify:\n",
    "dataDir = \"C:/Users/dbaha/Documents/Data/V4_Megha_cranial/\"\n",
    "dataFilePrefix = ''\n",
    "startingFileNum = 0\n",
    "framesPerFile = 1000 # This is the default setting for the Miniscope software. If you changed it in software change it here too.\n",
    "# -------------------------------\n",
    "\n",
    "# TODO: Grab frames per file from metadate\n",
    "\n",
    "# Makes sure path ends with '/'\n",
    "if (dataDir[-1] is not \"/\"):\n",
    "    dataDir = dataDir + \"/\""
   ]
  },
  {
   "source": [
    "We will now play back the video and calculate the mean 2D FFT of the played back frames. You can chage 'frameStep' to speed this up. We generally don't need tons of frames for calculating the mean 2D FFT of the video."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run through avi files and generate mean fft\n",
    "\n",
    "# Values users can modify:\n",
    "frameStep = 10 # Can use frame skipping to speed this up\n",
    "showVideo = True\n",
    "# -----------------------\n",
    "\n",
    "fileNum = startingFileNum\n",
    "sumFFT = None\n",
    "applyVignette = True\n",
    "vignetteCreated = False\n",
    "running = True\n",
    "\n",
    "while (path.exists(dataDir + dataFilePrefix + \"{:.0f}.avi\".format(fileNum)) and running is True):\n",
    "    cap = cv2.VideoCapture(dataDir + dataFilePrefix + \"{:.0f}.avi\".format(fileNum))\n",
    "    fileNum = fileNum + 1\n",
    "    frameNum = 0\n",
    "    for frameNum in tqdm(range(0,framesPerFile, frameStep), total = framesPerFile/frameStep, desc =\"Running file {:.0f}.avi\".format(fileNum - 1)):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if (vignetteCreated is False):\n",
    "            rows, cols = frame.shape[:2] \n",
    "            X_resultant_kernel = cv2.getGaussianKernel(cols,cols/4) \n",
    "            Y_resultant_kernel = cv2.getGaussianKernel(rows,rows/4) \n",
    "            resultant_kernel = Y_resultant_kernel * X_resultant_kernel.T \n",
    "            mask = 255 * resultant_kernel / np.linalg.norm(resultant_kernel)\n",
    "            vignetteCreated = True\n",
    "\n",
    "        if applyVignette is False:\n",
    "            mask = mask * 0 + 1\n",
    "        \n",
    "        if (ret is False):\n",
    "            break\n",
    "        else:\n",
    "            frame = frame[:,:,1] * mask\n",
    "            \n",
    "            dft = cv2.dft(np.float32(frame),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "            dft_shift = np.fft.fftshift(dft)\n",
    "             \n",
    "            try:\n",
    "                sumFFT = sumFFT + cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1])\n",
    "            except:\n",
    "                sumFFT = cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1])\n",
    "\n",
    "            if (showVideo is True):\n",
    "                cv2.imshow(\"Vid\", frame/255)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    running = False\n",
    "                    break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "We will now display the mean 2D FFT and show what sort of spatial filtering we want to apply. Generally the V4 Miniscope noise shows up as a vertical line with a few bright spots (these are the spatial frequencies related to the dim, scrolling horizontal stripes).\n",
    "\n",
    "We want to filter these stripes out while not disturbing the actual imaging data. \n",
    "\n",
    "Below shows an example mean 2D FFT. Spatial frequencies due to the horizontal lines show up in the red boxes. The spatial frequencies in the green circle are mostly from the real data and you want to keep as much of this as possible while still removing most of the horizontal stripes.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"300\" src=\"img\\2D-FFT-example.PNG\">\n",
    "</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify FFT using a circle mask around center\n",
    "\n",
    "# Values users can modify:\n",
    "goodRadius = 2000\n",
    "notchHalfWidth = 3\n",
    "centerHalfHeightToLeave = 20\n",
    "# -----------------------\n",
    "\n",
    "crow,ccol = int(rows/2) , int(cols/2)\n",
    "\n",
    "maskFFT = np.zeros((rows,cols,2), np.float32)\n",
    "cv2.circle(maskFFT,(crow,ccol),goodRadius,1,thickness=-1)\n",
    "\n",
    "# for i in cutFreq:\n",
    "#     maskFFT[(i + crow-notchHalfWidth):(i+crow+notchHalfWidth),(ccol-notchHalfWidth):(ccol+notchHalfWidth),0] = 0\n",
    "#     maskFFT[(-i + crow-notchHalfWidth):(-i+crow+notchHalfWidth),(ccol-notchHalfWidth):(ccol+notchHalfWidth),0] = 0\n",
    "maskFFT[(crow+centerHalfHeightToLeave):,(ccol-notchHalfWidth):(ccol+notchHalfWidth),0] = 0\n",
    "maskFFT[:(crow-centerHalfHeightToLeave),(ccol-notchHalfWidth):(ccol+notchHalfWidth),0] = 0\n",
    "\n",
    "maskFFT[:,:,1] = maskFFT[:,:,0]\n",
    "\n",
    "\n",
    "modifiedFFT = sumFFT * maskFFT[:,:,0]\n",
    "\n",
    "# Plot original and modified FFT\n",
    "plt.figure()\n",
    "plt.subplot(121),plt.imshow(np.log(sumFFT), cmap = 'gray')\n",
    "plt.title('Mean FFT of Data')\n",
    "plt.subplot(122),plt.imshow(np.log(modifiedFFT), cmap = 'gray')\n",
    "plt.title('Filtered FFT')"
   ]
  },
  {
   "source": [
    "Now we will display the raw, filtered, and difference video.\n",
    "\n",
    "If things were done correctly, the filtered video show have the horizontal stripes removed and the difference video should pretty much only show those stripes (with maybe a tiny bit of other horizontal structure)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display filtered vs original videos\n",
    "\n",
    "# Values users can modify:\n",
    "frameStep = 3 # This will speed up the playback\n",
    "# -----------------------\n",
    "\n",
    "fileNum = startingFileNum\n",
    "sumFFT = None\n",
    "running = True\n",
    "\n",
    "while (path.exists(dataDir + dataFilePrefix + \"{:.0f}.avi\".format(fileNum)) and running is True):\n",
    "    cap = cv2.VideoCapture(dataDir + dataFilePrefix + \"{:.0f}.avi\".format(fileNum))\n",
    "    fileNum = fileNum + 1\n",
    "    for frameNum in tqdm(range(0,framesPerFile, frameStep), total = framesPerFile/frameStep, desc =\"Running file {:.0f}.avi\".format(fileNum - 1)):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if (ret is False):\n",
    "            break\n",
    "        else:\n",
    "            frame = frame[:,:,1]\n",
    "            dft = cv2.dft(np.float32(frame),flags = cv2.DFT_COMPLEX_OUTPUT|cv2.DFT_SCALE)\n",
    "            dft_shift = np.fft.fftshift(dft)\n",
    "             \n",
    "            fshift = dft_shift * maskFFT\n",
    "            f_ishift = np.fft.ifftshift(fshift)\n",
    "            img_back = cv2.idft(f_ishift)\n",
    "            img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])\n",
    "            \n",
    "            img_back[img_back >255] = 255\n",
    "            img_back = np.uint8(img_back)\n",
    "\n",
    "            im_diff = (128 + (frame - img_back)*2)\n",
    "            im_v = cv2.hconcat([frame, img_back, im_diff])\n",
    "            cv2.imshow(\"Raw, Filtered, Difference\", im_v/255)\n",
    "\n",
    "            try:\n",
    "                sumFFT = sumFFT + cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1])\n",
    "            except:\n",
    "                sumFFT = cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1])\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                running = False\n",
    "                break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "Now we will correct the other source of V4 Miniscope noise. This is a fast, ~+3Hz fluctuation of the brightness of the entire field of view. \n",
    "\n",
    "* We will first run through the data and calculate the mean intensity of every frame.\n",
    "* Next we will apply a lowpass filter to the mean intensity over time\n",
    "* Finally we will scale the imaging data by the percentage difference of raw and filtered mean intensity."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate mean fluorescence per frame\n",
    "\n",
    "# Users shouldn't change anything here\n",
    "frameStep = 1 # Should stay as 1\n",
    "fileNum = startingFileNum\n",
    "sumFFT = None\n",
    "meanFrameList = []\n",
    "\n",
    "\n",
    "while (path.exists(dataDir + dataFilePrefix + \"{:.0f}.avi\".format(fileNum))):\n",
    "    cap = cv2.VideoCapture(dataDir + dataFilePrefix + \"{:.0f}.avi\".format(fileNum))\n",
    "    fileNum = fileNum + 1\n",
    "    for frameNum in tqdm(range(0,framesPerFile, frameStep), total = framesPerFile/frameStep, desc =\"Running file {:.0f}.avi\".format(fileNum - 1)):\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if (ret is False):\n",
    "            break\n",
    "        else:\n",
    "            frame = frame[:,:,1]\n",
    "            dft = cv2.dft(np.float32(frame),flags = cv2.DFT_COMPLEX_OUTPUT|cv2.DFT_SCALE)\n",
    "            dft_shift = np.fft.fftshift(dft)\n",
    "             \n",
    "            fshift = dft_shift * maskFFT\n",
    "            f_ishift = np.fft.ifftshift(fshift)\n",
    "            img_back = cv2.idft(f_ishift)\n",
    "            img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])\n",
    "            meanFrameList.append(img_back.mean())\n",
    "            \n",
    "            # clear_output(wait=True)\n",
    "\n",
    "            # plt.subplot(121),plt.imshow(frame, cmap = 'gray')\n",
    "            # plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "            # plt.subplot(122),plt.imshow(img_back, cmap = 'gray')\n",
    "            # plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "            # plt.show()\n",
    "meanFrame = np.array(meanFrameList)"
   ]
  },
  {
   "source": [
    "Now we will generate a lowpass filter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a lowpass filter\n",
    "# Sample rate and desired cutoff frequencies (in Hz).\n",
    "\n",
    "# Values users can modify:\n",
    "fs = 30 # TODO: Should get this from timestamp file\n",
    "cutoff = 3.0\n",
    "# -----------------------\n",
    "\n",
    "plt.figure()\n",
    "for order in [3, 6, 9]:\n",
    "    b, a = butter(order, cutoff/ (0.5 * fs), btype='low', analog = False)\n",
    "    w, h = freqz(b, a, worN=2000)\n",
    "    plt.plot((fs * 0.5 / np.pi) * w, abs(h), label=\"order = %d\" % order)\n",
    "\n",
    "plt.plot([0, 0.5 * fs], [np.sqrt(0.5), np.sqrt(0.5)],\n",
    "             '--', label='sqrt(0.5)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Gain')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "# Plot Mean Frame Resuls\n",
    "# plt.figure(figsize=(8,4))\n",
    "# plt.plot(meanFrame)"
   ]
  },
  {
   "source": [
    "Now select which order of the filter you want to use and then we will apply that filter to the mean intensity of frames across the recording.\n",
    "\n",
    "Zoom into the plotted traces to check if the filtering removed high freqency noise but left the rest of the mean intensity trace unchanged.\n",
    "\n",
    "It should look something like this with the Filtered Data following the trend of the Raw Data but with the higher frequency fluctuations removed:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"400\" src=\"img\\filtered_data_example.PNG\">\n",
    "</p>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot effect of filtering\n",
    "\n",
    "# Values users can modify:\n",
    "butterOrder = 6\n",
    "# -----------------------\n",
    "\n",
    "b, a = butter(butterOrder, cutoff/ (0.5 * fs), btype='low', analog = False)\n",
    "meanFiltered = filtfilt(b,a,meanFrame)\n",
    "plt.figure()\n",
    "plt.plot(meanFrame, 'k', label='Raw Data')\n",
    "plt.plot( meanFiltered, label='Filtered Data')\n",
    "plt.plot(meanFrame - meanFiltered,'r', label='Difference')\n",
    "plt.xlabel('frame number')\n",
    "# plt.hlines([-a, a], 0, T, linestyles='--')\n",
    "plt.grid(True)\n",
    "plt.axis('tight')\n",
    "plt.legend(loc='upper left')\n",
    "# meanFrame[3000]"
   ]
  },
  {
   "source": [
    "Finally we will apply both the 2D FFT spatial filtering and the lowpass mean intensity filtering to the raw data.\n",
    "\n",
    "You can select between displaying the results and saving the results. If saving, the 'frameStep' should be set to 1.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply FFT spatial filtering and lowpass filtering to data and has the option of saving as new videos\n",
    "\n",
    "# Values users can modify:\n",
    "# Select one below -\n",
    "# mode = \"display\"\n",
    "mode = 'save'\n",
    "\n",
    "frameStep = 1 #1 # Should be set to 1 for saving\n",
    "\n",
    "# Select one below -\n",
    "compressionCodec = \"FFV1\"\n",
    "# compressionCodec = \"GREY\"\n",
    "# --------------------\n",
    "\n",
    "fileNum = startingFileNum\n",
    "sumFFT = None\n",
    "frameCount = 0\n",
    "running = True\n",
    "\n",
    "if (mode is \"save\" and frameStep is not 1):\n",
    "    print(\"WARNING: You are only saving every {} frame!\".format(frameStep))\n",
    "\n",
    "codec = cv2.VideoWriter_fourcc(compressionCodec[0],compressionCodec[1],compressionCodec[2],compressionCodec[3])\n",
    "\n",
    "if (mode is \"save\" and not path.exists(dataDir + \"Denoised\")):\n",
    "    os.mkdir(dataDir + \"Denoised\")\n",
    "\n",
    "while (path.exists(dataDir + dataFilePrefix + \"{:.0f}.avi\".format(fileNum)) and running is True):\n",
    "    cap = cv2.VideoCapture(dataDir + dataFilePrefix + \"{:.0f}.avi\".format(fileNum))\n",
    "\n",
    "    if (mode is \"save\"):\n",
    "        writeFile = cv2.VideoWriter(dataDir + \"Denoised/\" + dataFilePrefix + \"denoised{:.0f}.avi\".format(fileNum),  \n",
    "                            codec, 60, (cols,rows), isColor=False) \n",
    "\n",
    "    fileNum = fileNum + 1\n",
    "    # frameNum = 0\n",
    "    for frameNum in tqdm(range(0,framesPerFile, frameStep), total = framesPerFile/frameStep, desc =\"Running file {:.0f}.avi\".format(fileNum - 1)):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        ret, frame = cap.read()\n",
    "        # frameNum = frameNum + frameStep \n",
    "        \n",
    "        # print(frameCount)\n",
    "        \n",
    "        if (ret is False):\n",
    "            break\n",
    "        else:\n",
    "            frame = frame[:,:,1]\n",
    "            dft = cv2.dft(np.float32(frame),flags = cv2.DFT_COMPLEX_OUTPUT|cv2.DFT_SCALE)\n",
    "            dft_shift = np.fft.fftshift(dft)\n",
    "             \n",
    "            fshift = dft_shift * maskFFT\n",
    "            f_ishift = np.fft.ifftshift(fshift)\n",
    "            img_back = cv2.idft(f_ishift)\n",
    "            img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])\n",
    "\n",
    "            meanF = img_back.mean()\n",
    "            img_back = img_back * (1 + (meanFiltered[frameCount] - meanF)/meanF)\n",
    "            img_back[img_back >255] = 255\n",
    "            img_back = np.uint8(img_back)\n",
    "\n",
    "            \n",
    "            \n",
    "            if (mode is \"save\"):\n",
    "                writeFile.write(img_back)\n",
    "\n",
    "            if (mode is \"display\"):\n",
    "                im_diff = (128 + (frame - img_back)*2)\n",
    "                im_v = cv2.hconcat([frame, img_back])\n",
    "                im_v = cv2.hconcat([im_v, im_diff])\n",
    "\n",
    "                im_v = cv2.hconcat([frame, img_back, im_diff])\n",
    "                cv2.imshow(\"Cleaned video\", im_v/255)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    running = False\n",
    "                    cap.release()\n",
    "                    break\n",
    "\n",
    "            frameCount = frameCount + 1\n",
    "\n",
    "    if (mode is \"save\"):\n",
    "        writeFile.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ]
}